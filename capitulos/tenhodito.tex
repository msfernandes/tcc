\clearpage

\subsection{Tenho Dito}

``Tenho Dito'' corresponde ao produto deste trabalho visível pelo usuário final. Trata-se de uma aplicação \textit{web}, desenvolvida utilizando a linguagem \textit{python} com o \textit{framework Django}, e tem como objetivo ser uma forma mais lúdica e amigável de visualização de alguns dados disponíveis nos \textit{webservices} de dados abertos da Câmara dos Deputados. Utiliza métodos de processamento de linguagem natural e aprendizado de máquina para extrair o perfil temático dos parlamentares, analisando o texto de seus discursos e proposições. Além disso, também é possível traçar os temas mais discutidos (tanto em propostas quanto nos próprios discursos) pelos deputados de uma determinada região ou por partidos.

A aplicação é divida em dois grandes módulos: \textit{nlp} e \textit{core}. O primeiro é responsável por todas as operações relacionadas ao processamento dos textos, o que inclui aprendizado de máquina. Já o segundo módulo é responsável pela parte \textit{web}. No momento de escrita desse trabalho, ainda não tinha sido implementado o segundo módulo. Entretanto, estão disponíveis alguns protótipos, que mostram as possíveis funcionalidades do sistema.

Conforme mencionado no item ``\textit{frameworks}'', em \ref{ferramentas}, a análise dos textos será realizada com o apoio das ferramentas:

\begin{itemize}
    \item \textbf{Plagiarism:} biblioteca em estado \textit{alpha} desenvolvida pelo professor orientador do autor desse trabalho, Fábio Macêdo Mendes, e possui uma série de funcionalidades utilizadas no pré-processamento dos textos, como extração de \textit{tokens}, \textit{stemização}, remoção de \textit{stop words}, geração de \textit{n-gramas} e geração de \textit{bag-of-words} (com os diferentes tipos de representação dos termos, descrito na seção \ref{sec:representação_dos_termos} desse trabalho). Apesar do foco ser a detecção de plágio em textos e códigos, as funcionalidades implementadas podem ser utilizadas em tarefas genéricas de PLN.
    \item \textbf{Textblob:} biblioteca \textit{python} para processamento de dados textuais. Ela fornece uma interface simples para realizar tarefas comuns de processamento de linguagem natural, como análise de sentimento e classificação, por exemplo. Utiliza a biblioteca \textit{NLTK}\footnote{http://www.nltk.org} para realizar essas tarefas.
\end{itemize}

\subsubsection{Classificação dos Discursos}

A classificação dos discursos é dividida em duas etapas. A primeira etapa consiste em, inicialmente, dividir o texto em parágrafos, para que a análise seja realizada com uma quantidade menor de texto, e em seguida os parágrafos são classificados entre ``conteúdo útil'' ou ``conteúdo não-útil''. Por exemplo, o trecho \textit{``Muito obrigado, nobre Deputado. Pelo PSOL de São Paulo, o nobre Líder Ivan Valente. V. Exª tem cinco minutos na tribuna.''} não representa um conteúdo significativo, da mesma forma que `\textit{`O SR. ALCEU MOREIRA - Sr. Presidente, primeiro a medida provisória, logicamente.''} também não agregaria nenhum valor à análise. Trechos como esses devem se classificados como ``conteúdo não-útil'' e descartados da análise temática. A segunda etapa do processamento é a classificação temática dos parágrafos classificados como ``conteúdo útil'', na etapa anterior.

Para ambas etapas o procedimento adotado é o mesmo, com algumas alterações nos classificadores. Primeiro, um classificador \textit{NaiveBayesClassifier}, implementado pela biblioteca \textit{textblob}, é instanciado, utilizando dois conjuntos de palavras iniciais, um para definir ``conteúdo não-útil'' e outro para ``conteúdo''. Os conjuntos de palavras podem ser encontrados no apêndice \ref{conjunto-palavras}.

Em seguida, todos os parágrafos são classificados e, dentre os que foram classificados com uma probabilidade maior que 80\%, os 100 melhores colocados são utilizados para realizar o treinamento inicial do classificador. A partir disso, é realizado um treinamento supervisionado, onde a aplicação sugere uma classe mais provável e um especialista humano diz se o trecho corresponde à classe sugerida, caso não seja ele deve fornecer a classe correta. Ao finalizar o treinamento supervisionado, todos os parágrafos são classificados novamente, agora com o classificador melhor treinado.

Vale observar que as classificações útil/não-útil sugeridas após a primeira fase normalmente correspondiam às corretas, ainda que isto não tenha sido medido explicitamente.

Com o resultado a primeira classificação, obtém-se um conjunto de parágrafos classificados como ``conteúdo'', que serão usados na classificação temática. De forma semelhante à primeira classificação, um classificador \textit{NaiveBayesClassifier} é instanciado, agora com um conjunto de palavras específico para cada tema. Os temas e seus respectivos conjuntos de palavras também se encontram no apêndice \ref{conjunto-palavras}.

Todos os parágrafos são classificados novamente e é gerado um conjunto com os melhores classificados, que é usado para realizar o treinamento inicial do classificador. Após esta etapa, acontece o treinamento supervisionado, onde um humano diz se a classificação sugerida faz sentido e indica a classe correta quando não faz.

Também é possível realizar um treinamento não supervisionado para ambos os classificadores, de forma que as sugestões de classificação são utilizadas para o treinamento sem a análise de um especialista.

A cada iteração da fase de treinamento todas as probabilidades dos textos adicionados ao classificador são recalculadas, o que implica no aumento significativo do tempo de processamento. Por isso, é utilizada uma ferramenta de \textit{cache}, possibilitando o armazenamento dos classificadores depois de cada atualização. Toda vez que for realizado um treinamento ou uma classificação será utilizado o último classificador armazenado em \textit{cache}, com o treinamento prévio.

Esta fase mostrou que alguns discursos são difíceis de classificar ou por terem um conteúdo fragmentado (ex.: parágrafo com apenas uma ou poucas palavras, como \textit{``-Rio de Janeiro''}) ou por conter um conteúdo que aborda mais de um tema simultaneamente (ex.: \textit{``Eu parei de jogar há quase 17 anos e há 15 anos eu criei o Instituto Esporte \& Educação - IEE, do qual sou Presidente, que trabalha com esporte e educação. E há 15 anos nós viajamos para cidades do Brasil que não têm acesso à prática motora na escola, que não têm estrutura, que não têm professores e, especialmente, que não têm a visão da educação física, do esporte, do movimento, da ação motora, da atividade motora como um fator de desenvolvimento, cuja presença é importante dentro da escola.''}). Espera-se investigar modelos como o \textit{Latent Dirichlet Allocation} que trata cada trecho como uma mistura de temas e não como pertencente a uma única categoria.

Esta fase inicial de classificação dos parágrafos do discurso será utilizada como subsídio para a classificação final de cada deputado. Cada parágrafo de discurso pode ser tratado como se fosse apenas a classe correspondete e a partir daí trataríamos a contagem das frequências temáticas como se fosse uma análise de \textit{bag-of-words} ordinária. Esta etapa ainda não foi iniciada e será implementada no TCC2.
